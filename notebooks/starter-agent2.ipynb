{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c266446",
   "metadata": {},
   "source": [
    "# imports and setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0a9c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2m01:20 AM\u001b[0m\u001b[37m\u001b[0m | \u001b[37m\u001b[2m1228436519.L:21 \u001b[0m\u001b[37m\u001b[0m | \u001b[37m\u001b[22mDEBUG    \u001b[0m | \u001b[37m\u001b[22msettings loaded as \n",
      "{\n",
      "  \"models\": {\n",
      "    \"hf\": {\n",
      "      \"chat\": \"meta-llama/Llama-3.2-3B-Instruct:together\",\n",
      "      \"reasoning\": \"zai-org/GLM-4.7-Flash:novita\",\n",
      "      \"structured_output\": \"Qwen/Qwen3-Coder-30B-A3B-Instruct:ovhcloud\",\n",
      "      \"embedding_snowflake\": \"Snowflake/snowflake-arctic-embed-l-v2.0\",\n",
      "      \"embedding_specter\": \"allenai/specter2_base\",\n",
      "      \"encoder\": \"m3rg-iitd/matscibert\",\n",
      "      \"reranker\": \"Qwen/Qwen3-Reranker-0.6B\",\n",
      "      \"router\": \"openai/gpt-oss-20b:together\"\n",
      "    },\n",
      "    \"nebius\": {\n",
      "      \"reasoning\": \"deepseek-ai/DeepSeek-V3.2\",\n",
      "      \"tool_user\": \"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
      "      \"chat\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-fast\",\n",
      "      \"embedding_baai_bge\": \"BAAI/bge-multilingual-gemma2\",\n",
      "      \"router\": \"openai/gpt-oss-20b\"\n",
      "    }\n",
      "  },\n",
      "  \"paths\": {\n",
      "    \"base_dir\": \"/home/rudy/code/lattice/src\",\n",
      "    \"data_dir\": \"/home/rudy/code/lattice/src/data\",\n",
      "    \"logs_dir\": \"/home/rudy/code/lattice/src/logs\",\n",
      "    \"agents_dir\": \"/home/rudy/code/lattice/src/agents\",\n",
      "    \"skills_dir\": \"/home/rudy/code/lattice/src/skills\",\n",
      "    \"tools_dir\": \"/home/rudy/code/lattice/src/tools\"\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from datetime import datetime\n",
    "\n",
    "from catppuccin.extras.rich_ctp import mocha\n",
    "from rich import pretty\n",
    "from rich.console import Console\n",
    "from rich.pretty import pprint\n",
    "\n",
    "pretty.install()\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")\n",
    "\n",
    "from src.config.settings import get_settings\n",
    "from src.utils.logger import create_logger, ChatPrinter\n",
    "\n",
    "console = Console(theme=mocha)\n",
    "settings = get_settings()\n",
    "logger = create_logger(path=settings.paths.logs_dir)\n",
    "printer = ChatPrinter()\n",
    "logger.debug(f\"settings loaded as \\n{settings.model_dump_json(indent=2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d5e162e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Dict, List, Optional, TypedDict, Literal\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    HumanMessage,\n",
    "    AIMessageChunk,\n",
    "    MessageLikeRepresentation,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    "    filter_messages,\n",
    "    get_buffer_string,\n",
    "    convert_to_openai_messages,\n",
    ")\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_nebius import ChatNebius\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, StateGraph, MessagesState\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.types import Command, interrupt\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "from pydantic.json_schema import SkipJsonSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "042ca44e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.backends.virtual_filesystem import VirtualFilesystem\n",
    "from src.prompts import (\n",
    "    planning_mode_systemm_prompt,\n",
    "    planning_structured_output,\n",
    ")\n",
    "from src.schemas import RESEARCH_PLAN_TEMPLATE, ResearchPlan\n",
    "from src.schemas.prompts import SystemPromptTemplate\n",
    "from src.tools.filesystem import create_filesystem_tools\n",
    "from src.tools.utils import tool_with_auto_doc, SkipSchema\n",
    "from src.utils.stats import accumulate_usage, add_usage_metadata\n",
    "\n",
    "version = \"0.0.1-alpha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a3bfb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesystem_tools = create_filesystem_tools(VirtualFilesystem())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e761ea",
   "metadata": {},
   "source": [
    "# state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39878632",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TodoItems(TypedDict):\n",
    "    content: str\n",
    "    subitems: List[str]\n",
    "\n",
    "\n",
    "# class UsageMetadata(TypedDict):\n",
    "#     input_tokens: int\n",
    "#     output_tokens: int\n",
    "#     total_tokens: int\n",
    "#     input_token_details: dict\n",
    "#     output_token_details: dict\n",
    "\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    # list of messages\n",
    "    messages: Annotated[List[MessageLikeRepresentation], add_messages]\n",
    "    # # running statistics\n",
    "    # # TODO: decide if this is even needed\n",
    "    # # are we doing mroe than one LLM call per node?\n",
    "    # # if no we dont need this\n",
    "    # usage_metadata: Annotated[UsageMetadata, add_usage_metadata] = {\n",
    "    #     \"input_tokens\": 0,\n",
    "    #     \"output_tokens\": 0,\n",
    "    #     \"total_tokens\": 0,\n",
    "    #     \"input_token_details\": {},\n",
    "    #     \"output_token_details\": {},\n",
    "    # }\n",
    "    # current mode\n",
    "    mode: Literal[\"ask\", \"planning\", \"execution\"]\n",
    "    # whatever the agent needs across all the modes\n",
    "    todo: List[TodoItems]\n",
    "    research_plan: str | ResearchPlan\n",
    "    plan_approval_status: Literal[\"pending\", \"rejected\", \"approved\"]\n",
    "    # thoughts\n",
    "    thoughts: Annotated[List[AIMessage], add_messages]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db90234b",
   "metadata": {},
   "source": [
    "# LLM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c87621fc",
   "metadata": {},
   "source": [
    "## structured output for ask node\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e7246b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AskNodeResponse(BaseModel):\n",
    "    message: str = Field(description=\"The response to the user message.\")\n",
    "    ready_to_draft_plan: bool = Field(\n",
    "        description=\"Classify if you have enough information to draft the research plan given the conversation history. You will recieve this after using the ready_to_draft_plan_tool.\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64febd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(\n",
    "    model=settings.models.nebius.tool_user,\n",
    "    api_key=settings.env.NEBIUS_API_KEY,\n",
    "    base_url=settings.env.NEBIUS_API_ENDPOINT,\n",
    "    max_completion_tokens=8192,\n",
    "    temperature=0.0,\n",
    "    top_p=0.7,\n",
    "    streaming=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae38eb33",
   "metadata": {},
   "source": [
    "# Graph\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2626f8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool_with_auto_doc\n",
    "def think_tool(reflection: str, state: SkipSchema[Dict] = None) -> str:\n",
    "    \"\"\"Strategic reflection and thinking tool. Use this tool to reflect on the conversation so far and what you should do next. Ask questions such as:\n",
    "    - What does the user want me to do next?\n",
    "    - What information do I have so far?\n",
    "    - Do I have enough information to give a final answer?\n",
    "    - If i am missing information, what should I ask for?\n",
    "\n",
    "    Args:\n",
    "        reflection (str): Your detailed reflection on the conversation so far. Your thought should not be more than 2 sentences.\n",
    "\n",
    "    Returns:\n",
    "        str: Confirmation that reflection was recorded for decision making\n",
    "    \"\"\"\n",
    "    return f\"Reflection recorded: {reflection}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2cba70b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2m01:20 AM\u001b[0m\u001b[37m\u001b[0m | \u001b[37m\u001b[2m2770952278.L:26 \u001b[0m\u001b[37m\u001b[0m | \u001b[37m\u001b[22mDEBUG    \u001b[0m | \u001b[37m\u001b[22m# Helper: SYSTEM PROMPT\n",
      "\n",
      "## PROFILE\n",
      "- NAME: Assistant\n",
      "- ROLE: Helper\n",
      "- DESCRIPTION: You are a helpful and thoughtful assistant who thinks before answering\n",
      "- MODE: ASK\n",
      "- DATE: February 2026\n",
      "\n",
      "## TRAITS\n",
      "Your core traits are:\n",
      "- helpful\n",
      "- friendly\n",
      "\n",
      "## TOOLS\n",
      "You have access to the following tools:\n",
      "- `think_tool`: Use this tool to reflect and think strategically. Use your reflections to refine your next course of action. You are allowed to call this tool a maximum of 5 times.\n",
      "\n",
      "## SKILLS\n",
      "None - You do not have access to any skills yet.\n",
      "\n",
      "## DOMAIN KNOWLEDGE\n",
      "None - You do not have any domain knowledge yet.\n",
      "\n",
      "## WORKFLOW\n",
      "Given a user query, broadly follow the below steps:\n",
      "1. Judge if the query is complex. \n",
      "    a. Look at the conversation history to understand if the current context of the conversation is complex or straightforward.\n",
      "    b. Straightforward queries are usually like:\n",
      "        - small talk (eg: \"how are you?\", \"how can you help me?\" etc)\n",
      "        - basic questions (eg: simple arithmetic, questions about universal facts etc)\n",
      "2. if the query is deemed to be straightforward, then answer the question directly.\n",
      "3. if the query is deemed complex, \n",
      "    a. use the `think_tool` to think and reflect. You should ideally think about:\n",
      "        - what information you need to answer the user's question\n",
      "        - if you have those information available\n",
      "        - if you need more information, how should you collect it\n",
      "        - once you have all information, how should you respond\n",
      "        - what follow up's can the user come up with\n",
      "        - how can you tackle those follow up's\n",
      "    b. for each thought, make a single call for `think_tool`\n",
      "\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "short_system_prompt = SystemPromptTemplate(\n",
    "    name=\"Assistant\",\n",
    "    node_name=\"Helper\",\n",
    "    description=\"You are a helpful and thoughtful assistant who thinks before answering\",\n",
    "    tools=\"\"\"You have access to the following tools:\n",
    "- `think_tool`: Use this tool to reflect and think strategically. Use your reflections to refine your next course of action. You are allowed to call this tool a maximum of 5 times.\n",
    "\"\"\",\n",
    "    workflow=\"\"\"Given a user query, broadly follow the below steps:\n",
    "1. Judge if the query is complex. \n",
    "    a. Look at the conversation history to understand if the current context of the conversation is complex or straightforward.\n",
    "    b. Straightforward queries are usually like:\n",
    "        - small talk (eg: \"how are you?\", \"how can you help me?\" etc)\n",
    "        - basic questions (eg: simple arithmetic, questions about universal facts etc)\n",
    "2. if the query is deemed to be straightforward, then answer the question directly.\n",
    "3. if the query is deemed complex, \n",
    "    a. use the `think_tool` to think and reflect. You should ideally think about:\n",
    "        - what information you need to answer the user's question\n",
    "        - if you have those information available\n",
    "        - if you need more information, how should you collect it\n",
    "        - once you have all information, how should you respond\n",
    "        - what follow up's can the user come up with\n",
    "        - how can you tackle those follow up's\n",
    "    b. for each thought, make a single call for `think_tool`\n",
    "\"\"\",\n",
    ")\n",
    "logger.debug(short_system_prompt.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bf83039",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(\n",
    "    model=settings.models.nebius.tool_user,\n",
    "    api_key=settings.env.NEBIUS_API_KEY,\n",
    "    base_url=settings.env.NEBIUS_API_ENDPOINT,\n",
    "    max_completion_tokens=8192,\n",
    "    temperature=0.0,\n",
    "    top_p=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9d70b2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_node(state: AgentState) -> AgentState | Dict:\n",
    "    full_context = (\n",
    "        [SystemMessage(content=short_system_prompt.to_markdown())]\n",
    "        + state[\"messages\"]\n",
    "        + [SystemMessage(\"Following are your previous thoughts\")]\n",
    "        + state[\"thoughts\"]\n",
    "    )\n",
    "    bound_llm = bound_llm = chat_llm.bind_tools(\n",
    "        tools=[\n",
    "            think_tool,\n",
    "        ],\n",
    "        strict=True,\n",
    "        tool_choice=\"auto\",\n",
    "        parallel_tool_calls=True,\n",
    "    )\n",
    "    response = bound_llm.invoke(full_context)\n",
    "    thoughts = []\n",
    "    if response.tool_calls:\n",
    "        for tool_call in response.tool_calls:\n",
    "            if tool_call[\"name\"] == \"think_tool\":\n",
    "                thoughts.append(tool_call[\"args\"][\"reflection\"])\n",
    "    return {\"messages\": [response], \"thoughts\": thoughts}\n",
    "\n",
    "\n",
    "tool_node = ToolNode([think_tool])\n",
    "\n",
    "\n",
    "def tool_or_end_router(state: AgentState) -> Literal[\"tool\", \"end\"]:\n",
    "    last_message: AIMessage = state[\"messages\"][-1]\n",
    "    # if there are no tool calls then go to end\n",
    "    # else go back to tools\n",
    "    if last_message.tool_calls:\n",
    "        return \"tool\"\n",
    "    else:\n",
    "        return \"end\"\n",
    "\n",
    "\n",
    "graph = StateGraph(AgentState)\n",
    "graph.add_node(\"ask\", ask_node)\n",
    "graph.add_node(\"tool\", tool_node)\n",
    "graph.add_edge(START, \"ask\")\n",
    "graph.add_edge(\"tool\", \"ask\")\n",
    "graph.add_conditional_edges(\"ask\", tool_or_end_router, {\"tool\": \"tool\", \"end\": END})\n",
    "agent = graph.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "997bad8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #000080; text-decoration-color: #000080; font-weight: bold\">USER ï€‡ </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;34mUSER\u001b[0m\u001b[1;34m ï€‡ \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">  <span style=\"color: #000080; text-decoration-color: #000080\">explain the solution to quadratic equations</span>                                                                      \n",
       "</pre>\n"
      ],
      "text/plain": [
       "  \u001b[34mexplain the solution to quadratic equations\u001b[0m                                                                      \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\"mode = 'updates'\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\"mode = 'updates'\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\"m = AIMessage(content='', additional_kwargs={}, response_metadata={'finish_reason': 'tool_calls', 'model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'model_provider': 'openai'}, id='lc_run--019c3ed2-c4e6-7a20-b15a-84a49d15dd21', tool_calls=[{'name': 'think_tool', 'args': {'reflection': 'The user has asked for an explanation of the solution to quadratic equations. This is a straightforward query as it involves a well-known mathematical concept. I have the necessary domain knowledge to explain this topic clearly and accurately. I should provide a concise yet comprehensive explanation, including the standard form of a quadratic equation, the quadratic formula, and a simple example to illustrate the solution process.'}, 'id': 'chatcmpl-tool-b698ae1d11bf4e87a664e880611a99d3', 'type': 'tool_call'}], invalid_tool_calls=[])\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\"m = AIMessage\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcontent\u001b[0m\u001b[32m='', \u001b[0m\u001b[32madditional_kwargs\u001b[0m\u001b[32m=\u001b[0m\u001b[32m{\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32mresponse_metadata\u001b[0m\u001b[32m=\u001b[0m\u001b[32m{\u001b[0m\u001b[32m'finish_reason': 'tool_calls', 'model_name': 'Qwen/Qwen3-30B-A3B-Instruct-2507', 'model_provider': 'openai'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32mid\u001b[0m\u001b[32m='lc_run--019c3ed2-c4e6-7a20-b15a-84a49d15dd21', \u001b[0m\u001b[32mtool_calls\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m{\u001b[0m\u001b[32m'name': 'think_tool', 'args': \u001b[0m\u001b[32m{\u001b[0m\u001b[32m'reflection': 'The user has asked for an explanation of the solution to quadratic equations. This is a straightforward query as it involves a well-known mathematical concept. I have the necessary domain knowledge to explain this topic clearly and accurately. I should provide a concise yet comprehensive explanation, including the standard form of a quadratic equation, the quadratic formula, and a simple example to illustrate the solution process.'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, 'id': 'chatcmpl-tool-b698ae1d11bf4e87a664e880611a99d3', 'type': 'tool_call'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32minvalid_tool_calls\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m]\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\"mode = 'updates'\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\"mode = 'updates'\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\"m = ToolMessage(content='Reflection recorded: The user has asked for an explanation of the solution to quadratic equations. This is a straightforward query as it involves a well-known mathematical concept. I have the necessary domain knowledge to explain this topic clearly and accurately. I should provide a concise yet comprehensive explanation, including the standard form of a quadratic equation, the quadratic formula, and a simple example to illustrate the solution process.', name='think_tool', id='5d72d0ec-b7cd-446c-9df2-abed5ba4d42a', tool_call_id='chatcmpl-tool-b698ae1d11bf4e87a664e880611a99d3')\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\"m = ToolMessage\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcontent\u001b[0m\u001b[32m='Reflection recorded: The user has asked for an explanation of the solution to quadratic equations. This is a straightforward query as it involves a well-known mathematical concept. I have the necessary domain knowledge to explain this topic clearly and accurately. I should provide a concise yet comprehensive explanation, including the standard form of a quadratic equation, the quadratic formula, and a simple example to illustrate the solution process.', \u001b[0m\u001b[32mname\u001b[0m\u001b[32m='think_tool', \u001b[0m\u001b[32mid\u001b[0m\u001b[32m='5d72d0ec-b7cd-446c-9df2-abed5ba4d42a', \u001b[0m\u001b[32mtool_call_id\u001b[0m\u001b[32m='chatcmpl-tool-b698ae1d11bf4e87a664e880611a99d3'\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">\"mode = 'updates'\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m\"mode = 'updates'\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'m = AIMessage(content=\"A **quadratic equation** is a second-degree polynomial equation of the form:\\\\n\\\\n$$\\\\nax^2 + bx + c = 0\\\\n$$\\\\n\\\\nwhere:\\\\n- $ a $, $ b $, and $ c $ are constants (real numbers),\\\\n- $ a \\\\\\\\neq 0 $ (if $ a = 0 $, it\\'s not quadratic anymore).\\\\n\\\\n---\\\\n\\\\n### ðŸ”¢ **Solving Quadratic Equations: The Quadratic Formula**\\\\n\\\\nThe most general method to solve any quadratic equation is using the **quadratic formula**:\\\\n\\\\n$$\\\\nx = \\\\\\\\frac{-b \\\\\\\\pm \\\\\\\\sqrt{b^2 - 4ac}}{2a}\\\\n$$\\\\n\\\\nThis formula gives the two solutions (roots) of the equation. The term under the square root, $ b^2 - 4ac $, is called the **discriminant**.\\\\n\\\\n---\\\\n\\\\n### ðŸ“Œ **What the Discriminant Tells You:**\\\\n\\\\n- If $ b^2 - 4ac &gt; 0 $: Two **distinct real roots**\\\\n- If $ b^2 - 4ac = 0 $: One **repeated real root** (a perfect square)\\\\n- If $ b^2 - 4ac &lt; 0 $: Two **complex (imaginary) roots**\\\\n\\\\n---\\\\n\\\\n### âœ… **Example: Solve $ x^2 - 5x + 6 = 0 $**\\\\n\\\\nHere, $ a = 1 $, $ b = -5 $, $ c = 6 $\\\\n\\\\nApply the formula:\\\\n\\\\n$$\\\\nx = \\\\\\\\frac{-(-5) \\\\\\\\pm \\\\\\\\sqrt{(-5)^2 - 4(1)(6)}}{2(1)} = \\\\\\\\frac{5 \\\\\\\\pm \\\\\\\\sqrt{25 - 24}}{2} = \\\\\\\\frac{5 \\\\\\\\pm \\\\\\\\sqrt{1}}{2}\\\\n$$\\\\n\\\\n$$\\\\nx = \\\\\\\\frac{5 + 1}{2} = 3 \\\\\\\\quad \\\\\\\\text{or} \\\\\\\\quad x = \\\\\\\\frac{5 - 1}{2} = 2\\\\n$$\\\\n\\\\nâœ… So, the solutions are $ x = 3 $ and $ x = 2 $\\\\n\\\\n---\\\\n\\\\n### ðŸ”„ Other Methods (Optional):\\\\n- **Factoring** (when possible)\\\\n- **Completing the square**\\\\n- **Graphing** (to find x-intercepts)\\\\n\\\\nBut the quadratic formula works for **all** quadratic equations.\\\\n\\\\nLet me know if you\\'d like to see a step-by-step example using factoring or completing the square! ðŸ˜Š\", additional_kwargs={}, response_metadata={\\'finish_reason\\': \\'stop\\', \\'model_name\\': \\'Qwen/Qwen3-30B-A3B-Instruct-2507\\', \\'model_provider\\': \\'openai\\'}, id=\\'lc_run--019c3ed2-ca87-7a81-8110-b989a0396164\\', tool_calls=[], invalid_tool_calls=[])'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'm = AIMessage\u001b[0m\u001b[32m(\u001b[0m\u001b[32mcontent\u001b[0m\u001b[32m=\u001b[0m\u001b[32m\"A\u001b[0m\u001b[32m **quadratic equation** is a second-degree polynomial equation of the form:\\\\n\\\\n$$\\\\nax^2 + bx + c = 0\\\\n$$\\\\n\\\\nwhere:\\\\n- $ a $, $ b $, and $ c $ are constants \u001b[0m\u001b[32m(\u001b[0m\u001b[32mreal numbers\u001b[0m\u001b[32m)\u001b[0m\u001b[32m,\\\\n- $ a \\\\\\\\neq 0 $ \u001b[0m\u001b[32m(\u001b[0m\u001b[32mif $ a = 0 $, it\\'s not quadratic anymore\u001b[0m\u001b[32m)\u001b[0m\u001b[32m.\\\\n\\\\n---\\\\n\\\\n### ðŸ”¢ **Solving Quadratic Equations: The Quadratic Formula**\\\\n\\\\nThe most general method to solve any quadratic equation is using the **quadratic formula**:\\\\n\\\\n$$\\\\nx = \\\\\\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m-b \\\\\\\\pm \\\\\\\\sqrt\u001b[0m\u001b[32m{\u001b[0m\u001b[32mb^2 - 4ac\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m2a\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n$$\\\\n\\\\nThis formula gives the two solutions \u001b[0m\u001b[32m(\u001b[0m\u001b[32mroots\u001b[0m\u001b[32m)\u001b[0m\u001b[32m of the equation. The term under the square root, $ b^2 - 4ac $, is called the **discriminant**.\\\\n\\\\n---\\\\n\\\\n### ðŸ“Œ **What the Discriminant Tells You:**\\\\n\\\\n- If $ b^2 - 4ac > 0 $: Two **distinct real roots**\\\\n- If $ b^2 - 4ac = 0 $: One **repeated real root** \u001b[0m\u001b[32m(\u001b[0m\u001b[32ma perfect square\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n- If $ b^2 - 4ac < 0 $: Two **complex \u001b[0m\u001b[32m(\u001b[0m\u001b[32mimaginary\u001b[0m\u001b[32m)\u001b[0m\u001b[32m roots**\\\\n\\\\n---\\\\n\\\\n### âœ… **Example: Solve $ x^2 - 5x + 6 = 0 $**\\\\n\\\\nHere, $ a = 1 $, $ b = -5 $, $ c = 6 $\\\\n\\\\nApply the formula:\\\\n\\\\n$$\\\\nx = \\\\\\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m-\u001b[0m\u001b[32m(\u001b[0m\u001b[32m-5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m \\\\\\\\pm \\\\\\\\sqrt\u001b[0m\u001b[32m{\u001b[0m\u001b[32m(\u001b[0m\u001b[32m-5\u001b[0m\u001b[32m)\u001b[0m\u001b[32m^2 - 4\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m(\u001b[0m\u001b[32m6\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m2\u001b[0m\u001b[32m(\u001b[0m\u001b[32m1\u001b[0m\u001b[32m)\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = \\\\\\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m5 \\\\\\\\pm \\\\\\\\sqrt\u001b[0m\u001b[32m{\u001b[0m\u001b[32m25 - 24\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m2\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = \\\\\\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m5 \\\\\\\\pm \\\\\\\\sqrt\u001b[0m\u001b[32m{\u001b[0m\u001b[32m1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m2\u001b[0m\u001b[32m}\u001b[0m\u001b[32m\\\\n$$\\\\n\\\\n$$\\\\nx = \\\\\\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m5 + 1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m2\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = 3 \\\\\\\\quad \\\\\\\\text\u001b[0m\u001b[32m{\u001b[0m\u001b[32mor\u001b[0m\u001b[32m}\u001b[0m\u001b[32m \\\\\\\\quad x = \\\\\\\\frac\u001b[0m\u001b[32m{\u001b[0m\u001b[32m5 - 1\u001b[0m\u001b[32m}\u001b[0m\u001b[32m{\u001b[0m\u001b[32m2\u001b[0m\u001b[32m}\u001b[0m\u001b[32m = 2\\\\n$$\\\\n\\\\nâœ… So, the solutions are $ x = 3 $ and $ x = 2 $\\\\n\\\\n---\\\\n\\\\n### ðŸ”„ Other Methods \u001b[0m\u001b[32m(\u001b[0m\u001b[32mOptional\u001b[0m\u001b[32m)\u001b[0m\u001b[32m:\\\\n- **Factoring** \u001b[0m\u001b[32m(\u001b[0m\u001b[32mwhen possible\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n- **Completing the square**\\\\n- **Graphing** \u001b[0m\u001b[32m(\u001b[0m\u001b[32mto find x-intercepts\u001b[0m\u001b[32m)\u001b[0m\u001b[32m\\\\n\\\\nBut the quadratic formula works for **all** quadratic equations.\\\\n\\\\nLet me know if you\\'d like to see a step-by-step example using factoring or completing the square! ðŸ˜Š\", \u001b[0m\u001b[32madditional_kwargs\u001b[0m\u001b[32m=\u001b[0m\u001b[32m{\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32mresponse_metadata\u001b[0m\u001b[32m=\u001b[0m\u001b[32m{\u001b[0m\u001b[32m\\'finish_reason\\': \\'stop\\', \\'model_name\\': \\'Qwen/Qwen3-30B-A3B-Instruct-2507\\', \\'model_provider\\': \\'openai\\'\u001b[0m\u001b[32m}\u001b[0m\u001b[32m, \u001b[0m\u001b[32mid\u001b[0m\u001b[32m=\\'lc_run--019c3ed2-ca87-7a81-8110-b989a0396164\\', \u001b[0m\u001b[32mtool_calls\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m]\u001b[0m\u001b[32m, \u001b[0m\u001b[32minvalid_tool_calls\u001b[0m\u001b[32m=\u001b[0m\u001b[32m[\u001b[0m\u001b[32m]\u001b[0m\u001b[32m)\u001b[0m\u001b[32m'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "msg = \"explain the solution to quadratic equations\"\n",
    "printer.user(msg)\n",
    "all_msgs = []\n",
    "all_tokens = []\n",
    "for chunk in agent.stream(\n",
    "    {\"messages\": [HumanMessage(msg)]},\n",
    "    stream_mode=\"updates\",\n",
    "):\n",
    "    for step, data in chunk.items():\n",
    "        messages = data.get(\"messages\", [])\n",
    "        for m in messages:\n",
    "            if isinstance(m, AIMessage):\n",
    "                # Tool calls interrupt streaming\n",
    "                if m.tool_calls:\n",
    "                    printer._ensure_stream_closed()\n",
    "                    for t in m.tool_calls:\n",
    "                        printer.tool(t[\"name\"], status=\"running\", args=t[\"args\"])\n",
    "                # Sometimes final structured content arrives here\n",
    "                # (only print if not already streamed token-wise)\n",
    "                if m.content and not m.tool_calls:\n",
    "                    # Only print if stream wasn't used\n",
    "                    if not printer._ai_stream_active:\n",
    "                        printer.ai(m.content)\n",
    "                # Usage metadata normally arrives here\n",
    "                if m.usage_metadata:\n",
    "                    printer._ensure_stream_closed()\n",
    "                    printer.token_usage(\n",
    "                        m.usage_metadata.get(\"input_tokens\", 0),\n",
    "                        m.usage_metadata.get(\"output_tokens\", 0),\n",
    "                        latency=0,\n",
    "                    )\n",
    "            elif isinstance(m, ToolMessage):\n",
    "                printer.tool(\n",
    "                    m.name,\n",
    "                    status=\"finished\",\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e27ed264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mAIMessageChunk\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'model_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'lc_run--019c3ed2-c4e6-7a20-b15a-84a49d15dd21'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'think_tool'\u001b[0m,\n",
       "            \u001b[32m'args'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "            \u001b[32m'id'\u001b[0m: \u001b[32m'chatcmpl-tool-b698ae1d11bf4e87a664e880611a99d3'\u001b[0m,\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'tool_call'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m,\n",
       "    \u001b[33minvalid_tool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33mtool_call_chunks\u001b[0m=\u001b[1m[\u001b[0m\n",
       "        \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'name'\u001b[0m: \u001b[32m'think_tool'\u001b[0m,\n",
       "            \u001b[32m'args'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'id'\u001b[0m: \u001b[32m'chatcmpl-tool-b698ae1d11bf4e87a664e880611a99d3'\u001b[0m,\n",
       "            \u001b[32m'index'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "            \u001b[32m'type'\u001b[0m: \u001b[32m'tool_call_chunk'\u001b[0m\n",
       "        \u001b[1m}\u001b[0m\n",
       "    \u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tokens[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "783b4181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m\"I\u001b[0m\u001b[32m'm functioning well, thank you for asking! I'm here and ready to help you with whatever you need. How can I assist you today? ðŸ˜Š\"\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'refusal'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m33\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m45\u001b[0m,\n",
       "            \u001b[32m'completion_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens_details'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_provider'\u001b[0m: \u001b[32m'openai'\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'Qwen/Qwen3-30B-A3B-Instruct-2507'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[3;35mNone\u001b[0m,\n",
       "        \u001b[32m'id'\u001b[0m: \u001b[32m'chatcmpl-dfe1227f9d1b4e02a2aa048fe4c5b2f4'\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'lc_run--019c3ed1-5ef1-7f02-bb59-98ff510a4bba-0'\u001b[0m,\n",
       "    \u001b[33mtool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33minvalid_tool_calls\u001b[0m=\u001b[1m[\u001b[0m\u001b[1m]\u001b[0m,\n",
       "    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
       "        \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m33\u001b[0m,\n",
       "        \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m45\u001b[0m,\n",
       "        \u001b[32m'input_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'output_token_details'\u001b[0m: \u001b[1m{\u001b[0m\u001b[1m}\u001b[0m\n",
       "    \u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm.invoke([HumanMessage(\"How are you?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04faceee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lattice (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
