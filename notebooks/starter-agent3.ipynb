{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db2c39ca",
   "metadata": {},
   "source": [
    "# imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6c1946de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31e08ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2m10:54 AM\u001b[0m\u001b[37m\u001b[0m | \u001b[37m\u001b[2m3591201115.L:17 \u001b[0m\u001b[37m\u001b[0m | \u001b[37m\u001b[22mDEBUG    \u001b[0m | \u001b[37m\u001b[22msettings loaded as \n",
      "{\n",
      "  \"models\": {\n",
      "    \"hf\": {\n",
      "      \"chat\": \"meta-llama/Llama-3.2-3B-Instruct:together\",\n",
      "      \"reasoning\": \"zai-org/GLM-4.7-Flash:novita\",\n",
      "      \"structured_output\": \"Qwen/Qwen3-Coder-30B-A3B-Instruct:ovhcloud\",\n",
      "      \"embedding_snowflake\": \"Snowflake/snowflake-arctic-embed-l-v2.0\",\n",
      "      \"embedding_specter\": \"allenai/specter2_base\",\n",
      "      \"encoder\": \"m3rg-iitd/matscibert\",\n",
      "      \"reranker\": \"Qwen/Qwen3-Reranker-0.6B\",\n",
      "      \"router\": \"openai/gpt-oss-20b:together\"\n",
      "    },\n",
      "    \"nebius\": {\n",
      "      \"reasoning\": \"deepseek-ai/DeepSeek-V3.2\",\n",
      "      \"tool_user\": \"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
      "      \"chat\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-fast\",\n",
      "      \"embedding_baai_bge\": \"BAAI/bge-multilingual-gemma2\",\n",
      "      \"router\": \"openai/gpt-oss-20b\"\n",
      "    }\n",
      "  },\n",
      "  \"paths\": {\n",
      "    \"base_dir\": \"/home/rudy/code/lattice/src\",\n",
      "    \"data_dir\": \"/home/rudy/code/lattice/src/data\",\n",
      "    \"logs_dir\": \"/home/rudy/code/lattice/src/logs\",\n",
      "    \"agents_dir\": \"/home/rudy/code/lattice/src/agents\",\n",
      "    \"skills_dir\": \"/home/rudy/code/lattice/src/skills\",\n",
      "    \"tools_dir\": \"/home/rudy/code/lattice/src/tools\",\n",
      "    \"agentfs_dir\": \"/home/rudy/code/lattice/src/.agentfs\"\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "from typing import Annotated, Callable, Dict, List, Literal, Optional, TypedDict\n",
    "\n",
    "from catppuccin.extras.rich_ctp import mocha\n",
    "from rich import pretty\n",
    "from rich.console import Console\n",
    "from rich.pretty import pprint\n",
    "\n",
    "from src.config.settings import get_settings\n",
    "from src.utils.logger import ChatPrinter, create_logger\n",
    "\n",
    "console = Console(theme=mocha)\n",
    "settings = get_settings()\n",
    "logger = create_logger(path=settings.paths.logs_dir)\n",
    "printer = ChatPrinter()\n",
    "logger.debug(f\"settings loaded as \\n{settings.model_dump_json(indent=2)}\")\n",
    "\n",
    "pretty.install()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25434378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents.middleware import FilesystemMiddleware, SummarizationMiddleware\n",
    "from langchain.agents import create_agent\n",
    "from langchain.agents.middleware import (\n",
    "    ModelRequest,\n",
    "    ModelResponse,\n",
    "    after_agent,\n",
    "    after_model,\n",
    "    hook_config,\n",
    "    wrap_model_call,\n",
    ")\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AIMessageChunk,\n",
    "    HumanMessage,\n",
    "    MessageLikeRepresentation,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    "    convert_to_openai_messages,\n",
    "    filter_messages,\n",
    "    get_buffer_string,\n",
    "    RemoveMessage,\n",
    ")\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import StructuredTool, tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_nebius import ChatNebius\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.runtime import Runtime\n",
    "from langgraph.types import Command, Overwrite, interrupt\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "from pydantic.json_schema import SkipJsonSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa190f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.backends import CustomBackend\n",
    "from src.prompts import (\n",
    "    ask_mode_system_prompt,\n",
    "    planning_mode_system_prompt,\n",
    "    planning_structured_output,\n",
    ")\n",
    "from src.schemas import (\n",
    "    RESEARCH_PLAN_TEMPLATE,\n",
    "    ResearchPlan,\n",
    "    SystemPromptTemplate,\n",
    ")\n",
    "from src.tools import (\n",
    "    USAGE_INSTRUCTIONS,\n",
    "    SkipSchema,\n",
    "    filter_tool_from_middleware_by_name,\n",
    "    switch_to_ask_mode_tool,\n",
    "    switch_to_execution_mode_tool,\n",
    "    switch_to_planning_mode_tool,\n",
    "    think_tool,\n",
    "    wrap_tool_with_doc_and_error_handling,\n",
    ")\n",
    "from src.utils.stats import accumulate_usage, add_usage_metadata\n",
    "\n",
    "version = \"0.0.1-alpha\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec7d6c8",
   "metadata": {},
   "source": [
    "# load file system backend\n",
    "\n",
    "also need to filter tools\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c32402d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tool_param_descriptions = {\n",
    "    \"ls\": {\"path\": \"Absolute path to the directory to list. Must start with '/'. \"},\n",
    "    \"read_file\": {\n",
    "        \"file_path\": \"Absolute path to the file to read. Must start with '/'\",\n",
    "        \"offset\": \"Line number to start reading from (0-indexed). Default: 0.\",\n",
    "        \"limit\": \"Maximum number of lines to read. Default: 2000.\",\n",
    "    },\n",
    "    \"write_file\": {\n",
    "        \"file_path\": \"Absolute path where the file should be created. Must start with '/'.\",\n",
    "        \"content\": \"String content to write to the file.\",\n",
    "    },\n",
    "    \"edit_file\": {\n",
    "        \"file_path\": \"Absolute path to the file to edit. Must start with '/'.\",\n",
    "        \"old_string\": \"Exact string to search for and replace. Must match exactly including whitespace and indentation.\",\n",
    "        \"new_content\": \"String to replace old_string with. Must be different from old_string.\",\n",
    "        \"replace_all\": \"If True, replace all occurrences. If False (default), old_string must be unique in the file or the edit fails.\",\n",
    "    },\n",
    "    \"glob\": {\n",
    "        \"pattern\": \"Glob pattern to match files against (e.g., `'*.py'`, `'**/*.txt'`).\",\n",
    "        \"path\": \"Base directory to search from. Defaults to root (`/`).\",\n",
    "    },\n",
    "    \"grep\": {\n",
    "        \"pattern\": ' Literal string to search for (NOT regex). Performs exact substring matching within file content. Example: \"TODO\" matches any line containing \"TODO\", but not \"TODOS\" or \"TO DO\".',\n",
    "        \"path\": 'Optional directory path to search in. If None, searches in current working directory. Example: \"/workspace/src\".',\n",
    "        \"glob\": \"\"\"Optional glob pattern to filter which FILES to search.\n",
    "Filters by filename/path, not content.\n",
    "Supports standard glob wildcards:\n",
    "- `*` matches any characters in filename\n",
    "- `**` matches any directories recursively\n",
    "- `?` matches single character\n",
    "- `[abc]` matches one character from set\"\"\",\n",
    "        \"output_mode\": \"\"\"Specifies format of grep output. Options:\n",
    "- file_with_matches: file paths only, default\n",
    "- content: matching lines with content\n",
    "- count: match counts per file\"\"\",\n",
    "    },\n",
    "}\n",
    "backend = CustomBackend()\n",
    "\n",
    "# so for the ask node\n",
    "# it will have access to only the ls and read_file tools\n",
    "ask_filesystem_mw = FilesystemMiddleware(backend=backend)\n",
    "for i in range(len(ask_filesystem_mw.tools)):\n",
    "    ask_filesystem_mw.tools[i].args_schema = wrap_tool_with_doc_and_error_handling(\n",
    "        ask_filesystem_mw.tools[i].func,\n",
    "        custom_name=ask_filesystem_mw.tools[i].name,\n",
    "        custom_description=ask_filesystem_mw.tools[i].description,\n",
    "        custom_param_descriptions=tool_param_descriptions.get(\n",
    "            ask_filesystem_mw.tools[i].name, {}\n",
    "        ),\n",
    "    ).args_schema\n",
    "ask_filesystem_mw = filter_tool_from_middleware_by_name(\n",
    "    ask_filesystem_mw, include=[\"ls\", \"read_file\"]\n",
    ")\n",
    "\n",
    "# # the planning node and execution node will have access to all the tools\n",
    "# filesystem_mw = FilesystemMiddleware(backend=backend)\n",
    "# for i in range(len(filesystem_mw.tools)):\n",
    "#     filesystem_mw.tools[i].args_schema = wrap_tool_with_doc_and_error_handling(\n",
    "#         filesystem_mw.tools[i].func,\n",
    "#         custom_name=filesystem_mw.tools[i].name,\n",
    "#         custom_description=filesystem_mw.tools[i].description,\n",
    "#         custom_param_descriptions=tool_param_descriptions.get(\n",
    "#             filesystem_mw.tools[i].name, {}\n",
    "#         ),\n",
    "#     ).args_schema\n",
    "# filesystem_mw = filter_tool_from_middleware_by_name(\n",
    "#     filesystem_mw,\n",
    "#     include=[\"ls\", \"read_file\", \"write_file\"],\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "eecd432a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"thread-5\"}}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4913284",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(MessagesState):\n",
    "    mode: Literal[\"ask\", \"planning\", \"execution\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4e85a5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer = MemorySaver()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5958425f",
   "metadata": {},
   "source": [
    "## ask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "90bb605c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_mode_system_prompt.workflow = \"\"\"Given a user query, broadly follow the below steps:\n",
    "1. Judge if the query is complex. \n",
    "    a. Look at the conversation history to understand if the current context of the conversation is complex or straightforward.\n",
    "    b. Straightforward queries are usually like:\n",
    "        - small talk (eg: \"how are you?\", \"how can you help me?\" etc)\n",
    "        - basic questions (eg: simple arithmetic, questions about universal facts etc)\n",
    "2. if the query is deemed to be straightforward, then answer the question directly.\n",
    "3. if the query is deemed complex, \n",
    "    a. use the `think_tool` to think and reflect. \n",
    "    b. for each thought, make a single call for `think_tool`\n",
    "    c. if you think you need some input from the user, do not use any tool and just send your response.\n",
    "    d. if you are unsure about anything, just ask the user.\n",
    "    e. based on new user input evaluate the current conversation context and proceed from step 2.\n",
    "4. once you deem the user has presented you with a query asking for help with their research literature survey and you have fulfilled all criteria to use the `switch_to_planning_mode_tool`, use it and proceed to the next mode.\n",
    "\"\"\"\n",
    "ask_mode_system_prompt.filesystem = \"\"\"\n",
    "You have access to a Virtual Sandboxed Filesystem with the following paths:\n",
    "- /notes/ : This directory is for your personal notes. These are things like:\n",
    "    * information you have gathered about the user's research topic\n",
    "    * quick notes you have taken while thinking and reflecting with the `think_tool`\n",
    "- /memories/ : You can store things that you wish to remember (hence \"memories\") here. These are things like:\n",
    "    * long term user preferences\n",
    "    * important past interactions\n",
    "    * user-specific knowledge\n",
    "\n",
    "Things to remember about interacting with the filesystem:\n",
    "- You will have access to some filesystem tools to interact with the filesystem. More details below.\n",
    "- Always use absolute paths starting with '/' when interacting with the filesystem.\n",
    "- You cannot create subdirectories in either /notes/ or /memories/.\n",
    "- When you write files, make sure to give them descriptive names so that you can easily find them later. \n",
    "- Files must be written in valid markdown format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "27185ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@wrap_model_call\n",
    "def ask_node(\n",
    "    request: ModelRequest, handler: Callable[[ModelRequest], ModelResponse]\n",
    ") -> ModelResponse:\n",
    "    # get information from the request\n",
    "    state = request.state\n",
    "    tools = request.tools\n",
    "    llm = request.model\n",
    "    # we need to serve the context to the ask node\n",
    "    # it contains\n",
    "    # - system prompt\n",
    "    # - all non tool messages messages with non-empty content\n",
    "    # - all tool messages except the ones from `think_tool`\n",
    "    # - thoughts\n",
    "    ask_mode_system_prompt.tools = (\n",
    "        \"You have access to the following tools\\n\"\n",
    "        + \"\\n\".join(\n",
    "            [\n",
    "                f\"- `{tool.name}` - {USAGE_INSTRUCTIONS[tool.name].get('desc', '')}\"\n",
    "                for tool in tools  # noqa: F811\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "    system_prompt = [SystemMessage(ask_mode_system_prompt.to_markdown())]\n",
    "    messages = [\n",
    "        _\n",
    "        for _ in state[\"messages\"]\n",
    "        if (len(_.content) > 0 and not isinstance(_, ToolMessage))\n",
    "        or (isinstance(_, ToolMessage) and _.name != \"think_tool\")\n",
    "    ]\n",
    "    # thoughts are recorded in tool messages\n",
    "    # response is recieved as \"Reflection recorded: {thought}\" from the think_tool, so we need to extract the actual thought from the response\n",
    "    thoughts = [\n",
    "        _.content[21:]\n",
    "        for _ in state[\"messages\"]\n",
    "        if isinstance(_, ToolMessage) and _.name == \"think_tool\"\n",
    "    ]\n",
    "    if thoughts:\n",
    "        thoughts = [\n",
    "            SystemMessage(\n",
    "                \"Your thoughts so far are given next: \\n\"\n",
    "                + \"\\n\".join([f\"{i}. {t}\" for i, t in enumerate(thoughts, 1)])\n",
    "            )\n",
    "        ]\n",
    "    full_context = system_prompt + messages + thoughts\n",
    "    bound_llm = llm.bind_tools(\n",
    "        tools=tools,\n",
    "        strict=True,\n",
    "        parallel_tool_calls=False,\n",
    "    )\n",
    "    response = bound_llm.invoke(full_context)\n",
    "    return ModelResponse(result=response)\n",
    "\n",
    "\n",
    "@after_model\n",
    "@hook_config(can_jump_to=[\"end\", \"tools\"])\n",
    "def ask_mode_response_router(state: AgentState, runtime: Runtime) -> Dict[str, any]:\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            if tool_call[\"name\"] == \"switch_to_planning_mode_tool\":\n",
    "                # if there is a call made to switch to planning mode\n",
    "                # then we will switch\n",
    "                return {\"jump_to\": \"end\", \"mode\": \"ask\"}\n",
    "        # if there is a tool call\n",
    "        # but after iterating over all calls we did not find switch to planning mode\n",
    "        # we can safely jump back to tools\n",
    "        return {\"jump_to\": \"tools\"}\n",
    "    else:\n",
    "        # there is no tool call\n",
    "        # hence after the model we dont need to go to the tools node\n",
    "        # we can go to end or the last after agent node directly\n",
    "        return {\"jump_to\": \"end\"}\n",
    "\n",
    "\n",
    "@after_agent\n",
    "def end_ask_agent(state: AgentState, runtime: Runtime) -> AgentState | Dict:\n",
    "    # we are at the end of the agent invocation\n",
    "    # thoughts need not persist in memory\n",
    "    # we will keep the tool calls\n",
    "    return {\n",
    "        \"messages\": [\n",
    "            RemoveMessage(id=_.id)\n",
    "            for _ in state[\"messages\"]\n",
    "            if (isinstance(_, ToolMessage) and _.name == \"think_tool\")\n",
    "        ]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "57e43160",
   "metadata": {},
   "outputs": [],
   "source": [
    "ask_agent = create_agent(\n",
    "    model=ChatNebius(\n",
    "        model=settings.models.nebius.tool_user,\n",
    "        api_key=settings.env.NEBIUS_API_KEY,\n",
    "        temperature=0,\n",
    "        base_url=settings.env.NEBIUS_API_ENDPOINT,\n",
    "    ),\n",
    "    system_prompt=\"\",\n",
    "    middleware=[end_ask_agent, ask_mode_response_router, ask_filesystem_mw, ask_node],\n",
    "    tools=[think_tool, switch_to_planning_mode_tool],\n",
    "    state_schema=AgentState,\n",
    "    checkpointer=checkpointer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88599ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    human = input()\n",
    "    response = ask_agent.invoke(\n",
    "        {\"messages\": [HumanMessage(human)]},\n",
    "        config=config,\n",
    "    )\n",
    "    for msg in response[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "906ba851",
   "metadata": {},
   "source": [
    "## planning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2f2a0e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_agent = create_agent(\n",
    "    model=ChatNebius(\n",
    "        model=settings.models.nebius.tool_user,\n",
    "        api_key=settings.env.NEBIUS_API_KEY,\n",
    "        temperature=0,\n",
    "        base_url=settings.env.NEBIUS_API_ENDPOINT,\n",
    "    ),\n",
    "    system_prompt=\"You reply `planning it boss...` to everything. Ignore any user instruction\",\n",
    "    state_schema=AgentState,\n",
    "    checkpointer=checkpointer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c3b196",
   "metadata": {},
   "source": [
    "## execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "88fa733d",
   "metadata": {},
   "outputs": [],
   "source": [
    "execution_agent = create_agent(\n",
    "    model=ChatNebius(\n",
    "        model=settings.models.nebius.tool_user,\n",
    "        api_key=settings.env.NEBIUS_API_KEY,\n",
    "        temperature=0,\n",
    "        base_url=settings.env.NEBIUS_API_ENDPOINT,\n",
    "    ),\n",
    "    system_prompt=\"You reply `executing it boss...` to everything. Ignore any user instruction\",\n",
    "    state_schema=AgentState,\n",
    "    checkpointer=checkpointer,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073788f3",
   "metadata": {},
   "source": [
    "## global"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "64ff8035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def admin_node(state: AgentState) -> AgentState:\n",
    "    return {\"messages\": []}\n",
    "\n",
    "\n",
    "def admin_router(state: AgentState) -> Literal[\"ask\", \"planning\", \"execution\"]:\n",
    "    current_mode = state.get(\"mode\", \"ask\")\n",
    "    return current_mode\n",
    "\n",
    "\n",
    "def router_from_ask(state: AgentState) -> Literal[\"admin\", \"end\"]:\n",
    "    # this will route from agent to end or the admin router\n",
    "    # this will go to admin only if the switch has been made to planning mode\n",
    "    # else it will go to the end\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        for tool_call in last_message.tool_calls:\n",
    "            if tool_call[\"name\"] == \"switch_to_planning_mode_tool\":\n",
    "                return \"admin\"\n",
    "    return \"end\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "5c91577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "supergraph = StateGraph(AgentState)\n",
    "supergraph.add_node(\"admin\", admin_node)\n",
    "supergraph.add_node(\"ask\", ask_agent)\n",
    "supergraph.add_node(\"planning\", planning_agent)\n",
    "supergraph.add_node(\"execution\", execution_agent)\n",
    "supergraph.add_edge(START, \"admin\")\n",
    "supergraph.add_conditional_edges(\n",
    "    \"admin\",\n",
    "    admin_router,\n",
    "    {\"ask\": \"ask\", \"planning\": \"planning\", \"execution\": \"execution\"},\n",
    ")\n",
    "supergraph.add_conditional_edges(\"ask\", router_from_ask, {\"admin\": \"admin\", \"end\": END})\n",
    "supergraph.add_edge(\"planning\", END)\n",
    "supergraph.add_edge(\"execution\", END)\n",
    "super_agent = supergraph.compile(checkpointer=checkpointer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "bcd612a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<langgraph.graph.state.CompiledStateGraph object at 0x7f47fb885110>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "super_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c408d823",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"thread-3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165305bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = agent.get_state(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cef01209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "help me do an introductory survey on RL post training methods for SLM's\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm ready to help you with an introductory survey on reinforcement learning (RL) post-training methods for small language models (SLMs). To get started, could you please clarify the following:\n",
      "\n",
      "1. What specific aspects of RL post-training methods for SLMs are you most interested in? (e.g., reward modeling, preference learning, fine-tuning strategies, scalability challenges, evaluation metrics)\n",
      "2. Are you focusing on any particular application domain (e.g., dialogue systems, code generation, summarization)?\n",
      "3. Do you have a preferred scope for the survey—broad overview, technical depth, or comparison of key methods?\n",
      "\n",
      "This will help me tailor the survey to your needs.\n",
      "None\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "help me do an introductory survey on RL post training methods for SLM's\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm ready to help you with an introductory survey on reinforcement learning (RL) post-training methods for small language models (SLMs). To get started, could you please clarify the following:\n",
      "\n",
      "1. What specific aspects of RL post-training methods for SLMs are you most interested in? (e.g., reward modeling, preference learning, fine-tuning strategies, scalability challenges, evaluation metrics)\n",
      "2. Are you focusing on any particular application domain (e.g., dialogue systems, code generation, summarization)?\n",
      "3. Do you have a preferred scope for the survey—broad overview, technical depth, or comparison of key methods?\n",
      "\n",
      "This will help me tailor the survey to your needs.\n",
      "None\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "i am interested in policy learning, and specifically for normal conversations. i want an introductory survey\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  think_tool (chatcmpl-tool-dd4e0ee37ed841da8b4912f9e13c97d2)\n",
      " Call ID: chatcmpl-tool-dd4e0ee37ed841da8b4912f9e13c97d2\n",
      "  Args:\n",
      "    reflection: The user is interested in RL post-training methods for small language models (SLMs), specifically policy learning for normal conversations. They want an introductory survey, indicating a need for foundational knowledge and key concepts. I should focus on explaining core RL methods in policy learning, their application to SLMs, and relevance to conversational AI, while keeping the overview accessible and structured.\n",
      "None\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: think_tool\n",
      "\n",
      "Reflection recorded: The user is interested in RL post-training methods for small language models (SLMs), specifically policy learning for normal conversations. They want an introductory survey, indicating a need for foundational knowledge and key concepts. I should focus on explaining core RL methods in policy learning, their application to SLMs, and relevance to conversational AI, while keeping the overview accessible and structured.\n",
      "None\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I'm ready to help you with an introductory survey on reinforcement learning (RL) post-training methods for small language models (SLMs), focusing on policy learning for normal conversations. To ensure the survey is well-structured and relevant, I’ll first clarify the scope and key components.\n",
      "\n",
      "Could you confirm the following:\n",
      "1. Should the survey include foundational RL concepts (e.g., reward signals, policy gradients) for readers who may be new to RL?\n",
      "2. Are you interested in specific RL algorithms (e.g., PPO, DPO, RLHF) or a broader overview of policy learning paradigms?\n",
      "3. Should the survey highlight challenges unique to applying RL to SLMs (e.g., data efficiency, computational constraints, overfitting)?\n",
      "\n",
      "This will help me shape the survey appropriately.\n",
      "None\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Command' object has no attribute 'result'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m      2\u001b[39m     human = \u001b[38;5;28minput\u001b[39m()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     response = \u001b[43magent\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhuman\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m msg \u001b[38;5;129;01min\u001b[39;00m response[\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m      5\u001b[39m         \u001b[38;5;28mprint\u001b[39m(msg.pretty_print())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\70086503\\code\\lattice\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:3071\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, **kwargs)\u001b[39m\n\u001b[32m   3068\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | Any] = []\n\u001b[32m   3069\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m3071\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   3072\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   3073\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3074\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3075\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mupdates\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m   3076\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m   3077\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3078\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3079\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3080\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3081\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3082\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdurability\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3083\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3084\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   3085\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   3086\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\70086503\\code\\lattice\\.venv\\Lib\\site-packages\\langgraph\\pregel\\main.py:2646\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, context, stream_mode, print_mode, output_keys, interrupt_before, interrupt_after, durability, subgraphs, debug, **kwargs)\u001b[39m\n\u001b[32m   2644\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2645\u001b[39m     loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2646\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2647\u001b[39m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2648\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2649\u001b[39m \u001b[43m    \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2650\u001b[39m \u001b[43m    \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2651\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2652\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2653\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprint_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubgraphs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqueue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mEmpty\u001b[49m\n\u001b[32m   2655\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2656\u001b[39m loop.after_tick()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\70086503\\code\\lattice\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_runner.py:167\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    165\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    166\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m167\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    175\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    176\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    177\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    178\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\70086503\\code\\lattice\\.venv\\Lib\\site-packages\\langgraph\\pregel\\_retry.py:42\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     40\u001b[39m     task.writes.clear()\n\u001b[32m     41\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m42\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     44\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\70086503\\code\\lattice\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:656\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    654\u001b[39m     \u001b[38;5;66;03m# run in context\u001b[39;00m\n\u001b[32m    655\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m set_config_context(config, run) \u001b[38;5;28;01mas\u001b[39;00m context:\n\u001b[32m--> \u001b[39m\u001b[32m656\u001b[39m         \u001b[38;5;28minput\u001b[39m = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    657\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    658\u001b[39m     \u001b[38;5;28minput\u001b[39m = step.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\70086503\\code\\lattice\\.venv\\Lib\\site-packages\\langgraph\\_internal\\_runnable.py:400\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    398\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m400\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\70086503\\code\\lattice\\.venv\\Lib\\site-packages\\langchain\\agents\\factory.py:1172\u001b[39m, in \u001b[36mcreate_agent.<locals>.model_node\u001b[39m\u001b[34m(state, runtime)\u001b[39m\n\u001b[32m   1169\u001b[39m     response = wrap_model_call_handler(request, _execute_model_sync)\n\u001b[32m   1171\u001b[39m \u001b[38;5;66;03m# Extract state updates from ModelResponse\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1172\u001b[39m state_updates = {\u001b[33m\"\u001b[39m\u001b[33mmessages\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m}\n\u001b[32m   1173\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.structured_response \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1174\u001b[39m     state_updates[\u001b[33m\"\u001b[39m\u001b[33mstructured_response\u001b[39m\u001b[33m\"\u001b[39m] = response.structured_response\n",
      "\u001b[31mAttributeError\u001b[39m: 'Command' object has no attribute 'result'",
      "During task with name 'model' and id '0693fe3e-d699-0815-8594-3ac8683a1b2a'"
     ]
    }
   ],
   "source": [
    "while True:\n",
    "    human = input()\n",
    "    response = agent.invoke({\"messages\": [HumanMessage(human)]}, config=config)\n",
    "    for msg in response[\"messages\"]:\n",
    "        msg.pretty_print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lattice (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
