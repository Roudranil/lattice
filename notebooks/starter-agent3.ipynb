{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c1946de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"..\" not in sys.path:\n",
    "    sys.path.insert(0, \"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d31e08ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[37m\u001b[2m11:14 AM\u001b[0m\u001b[37m\u001b[0m | \u001b[37m\u001b[2m2341847716.L:16 \u001b[0m\u001b[37m\u001b[0m | \u001b[37m\u001b[22mDEBUG    \u001b[0m | \u001b[37m\u001b[22msettings loaded as \n",
      "{\n",
      "  \"models\": {\n",
      "    \"hf\": {\n",
      "      \"chat\": \"meta-llama/Llama-3.2-3B-Instruct:together\",\n",
      "      \"reasoning\": \"zai-org/GLM-4.7-Flash:novita\",\n",
      "      \"structured_output\": \"Qwen/Qwen3-Coder-30B-A3B-Instruct:ovhcloud\",\n",
      "      \"embedding_snowflake\": \"Snowflake/snowflake-arctic-embed-l-v2.0\",\n",
      "      \"embedding_specter\": \"allenai/specter2_base\",\n",
      "      \"encoder\": \"m3rg-iitd/matscibert\",\n",
      "      \"reranker\": \"Qwen/Qwen3-Reranker-0.6B\",\n",
      "      \"router\": \"openai/gpt-oss-20b:together\"\n",
      "    },\n",
      "    \"nebius\": {\n",
      "      \"reasoning\": \"deepseek-ai/DeepSeek-V3.2\",\n",
      "      \"tool_user\": \"Qwen/Qwen3-30B-A3B-Instruct-2507\",\n",
      "      \"chat\": \"meta-llama/Meta-Llama-3.1-8B-Instruct-fast\",\n",
      "      \"embedding_baai_bge\": \"BAAI/bge-multilingual-gemma2\",\n",
      "      \"router\": \"openai/gpt-oss-20b\"\n",
      "    }\n",
      "  },\n",
      "  \"paths\": {\n",
      "    \"base_dir\": \"/home/rudy/code/lattice/src\",\n",
      "    \"data_dir\": \"/home/rudy/code/lattice/src/data\",\n",
      "    \"logs_dir\": \"/home/rudy/code/lattice/src/logs\",\n",
      "    \"agents_dir\": \"/home/rudy/code/lattice/src/agents\",\n",
      "    \"skills_dir\": \"/home/rudy/code/lattice/src/skills\",\n",
      "    \"tools_dir\": \"/home/rudy/code/lattice/src/tools\",\n",
      "    \"agentfs_dir\": \"/home/rudy/code/lattice/src/.agentfs\"\n",
      "  }\n",
      "}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "from catppuccin.extras.rich_ctp import mocha\n",
    "from rich import pretty\n",
    "from rich.console import Console\n",
    "from rich.pretty import pprint\n",
    "\n",
    "from src.config.settings import get_settings\n",
    "from src.utils.logger import ChatPrinter, create_logger\n",
    "\n",
    "console = Console(theme=mocha)\n",
    "settings = get_settings()\n",
    "logger = create_logger(path=settings.paths.logs_dir)\n",
    "printer = ChatPrinter()\n",
    "logger.debug(f\"settings loaded as \\n{settings.model_dump_json(indent=2)}\")\n",
    "\n",
    "pretty.install()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "25434378",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Dict, List, Literal, Optional, TypedDict\n",
    "\n",
    "from langchain_core.messages import (\n",
    "    AIMessage,\n",
    "    AIMessageChunk,\n",
    "    HumanMessage,\n",
    "    MessageLikeRepresentation,\n",
    "    SystemMessage,\n",
    "    ToolMessage,\n",
    "    convert_to_openai_messages,\n",
    "    filter_messages,\n",
    "    get_buffer_string,\n",
    ")\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.tools import StructuredTool, tool\n",
    "from langchain_core.utils.function_calling import convert_to_openai_tool\n",
    "from langchain_nebius import ChatNebius\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import END, START, MessagesState, StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.runtime import Runtime\n",
    "from langgraph.types import Command, Overwrite, interrupt\n",
    "from pydantic import BaseModel, Field, create_model\n",
    "from pydantic.json_schema import SkipJsonSchema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "caa190f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.backends.filesystem import VirtualFilesystem\n",
    "from src.prompts import (\n",
    "    ask_mode_system_prompt,\n",
    "    planning_mode_system_prompt,\n",
    "    planning_structured_output,\n",
    ")\n",
    "from src.schemas import (\n",
    "    RESEARCH_PLAN_TEMPLATE,\n",
    "    ResearchPlan,\n",
    "    SystemPromptTemplate,\n",
    ")\n",
    "from src.tools.filesystem import create_filesystem_tools\n",
    "from src.tools.thinking import (\n",
    "    switch_to_ask_mode_tool,\n",
    "    switch_to_execution_mode_tool,\n",
    "    switch_to_planning_mode_tool,\n",
    "    think_tool,\n",
    ")\n",
    "from src.tools.utils import SkipSchema, wrap_tool_with_doc_and_error_handling\n",
    "from src.utils.stats import accumulate_usage, add_usage_metadata\n",
    "\n",
    "version = \"0.0.1-alpha\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f7a0e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from deepagents.middleware import FilesystemMiddleware, SummarizationMiddleware\n",
    "from deepagents.backends import StateBackend, FilesystemBackend, CompositeBackend\n",
    "from deepagents import create_deep_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793b3161",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = lambda rt: CompositeBackend(\n",
    "    default=StateBackend(rt),\n",
    "    routes={\n",
    "        # treat filesystem as object and kv storage right now\n",
    "        # vfs proxies\n",
    "        \"/notes/\": StateBackend(rt),\n",
    "        # object store proxies\n",
    "        \"/memories/\": FilesystemBackend(\n",
    "            root_dir=settings.paths.agentfs_dir / \"memories\", virtual_mode=True\n",
    "        ),\n",
    "        \"/artifacts/\": FilesystemBackend(\n",
    "            root_dir=settings.paths.agentfs_dir / \"artifacts\", virtual_mode=True\n",
    "        ),\n",
    "    },\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fb30286",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesystem_mw = FilesystemMiddleware(backend=backend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "393e946c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filesystem_mw = FilesystemMiddleware(backend=backend)\n",
    "filesystem_mw.tools[0].args_schema = wrap_tool_with_doc_and_error_handling(\n",
    "    filesystem_mw.tools[0].func,\n",
    "    custom_name=filesystem_mw.tools[0].name,\n",
    "    custom_description=filesystem_mw.tools[0].description,\n",
    "    custom_param_descriptions={\n",
    "        \"path\": \"Path to directory or file. If directory, list of info for files in this directory is returned. If file, info for file is returned.\"\n",
    "    },\n",
    ").args_schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be9e6e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import create_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ac1a6bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lattice (3.11.11)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
